# 1) Setup
import os, pandas as pd, numpy as np
from dotenv import load_dotenv; load_dotenv()
from sqlalchemy import create_engine

engine = create_engine(os.getenv("POSTGRES_URL"))

# Helper: upsert dim with surrogate keys
def upsert_dim(df, table, business_key_cols, engine, dtype=None):
    with engine.begin() as conn:
        df.drop_duplicates(business_key_cols, inplace=True)
        df.to_sql(table, conn, schema="olist", if_exists="append", index=False, method="multi", chunksize=5000)

# 2) Load raw CSVs
p = "data"
customers = pd.read_csv(f"{p}/olist_customers_dataset.csv")
orders    = pd.read_csv(f"{p}/olist_orders_dataset.csv", parse_dates=[
    "order_purchase_timestamp","order_approved_at",
    "order_delivered_carrier_date","order_delivered_customer_date",
    "order_estimated_delivery_date"
])
items     = pd.read_csv(f"{p}/olist_order_items_dataset.csv", parse_dates=["shipping_limit_date"])
payments  = pd.read_csv(f"{p}/olist_order_payments_dataset.csv")
reviews   = pd.read_csv(f"{p}/olist_order_reviews_dataset.csv", parse_dates=[
    "review_creation_date","review_answer_timestamp"
])
products  = pd.read_csv(f"{p}/olist_products_dataset.csv")
catmap    = pd.read_csv(f"{p}/product_category_name_translation.csv")
sellers   = pd.read_csv(f"{p}/olist_sellers_dataset.csv")

# 3) Clean & enrich
products = products.merge(catmap, how="left",
                          left_on="product_category_name",
                          right_on="product_category_name").rename(
    columns={"product_category_name_english":"category_name_english",
             "product_category_name":"category_name"}
)

# Cut date dimension
date_cols = [
    "order_purchase_timestamp","order_approved_at",
    "order_delivered_carrier_date","order_delivered_customer_date",
    "order_estimated_delivery_date","shipping_limit_date",
    "review_creation_date","review_answer_timestamp"
]
dates = pd.unique(pd.concat([orders[c] for c in orders.columns if c.endswith("_timestamp")], axis=0).dropna().dt.date)
dates = np.unique(np.concatenate([
    dates,
    orders["order_purchase_timestamp"].dropna().dt.date.values,
    orders["order_approved_at"].dropna().dt.date.values,
    orders["order_delivered_carrier_date"].dropna().dt.date.values,
    orders["order_delivered_customer_date"].dropna().dt.date.values,
    orders["order_estimated_delivery_date"].dropna().dt.date.values,
    items["shipping_limit_date"].dropna().dt.date.values,
    reviews["review_creation_date"].dropna().dt.date.values,
    reviews["review_answer_timestamp"].dropna().dt.date.values
], axis=0))
dim_date = pd.DataFrame({"date_key": pd.to_datetime(dates)})
dim_date["year"]    = dim_date["date_key"].dt.year
dim_date["quarter"] = dim_date["date_key"].dt.quarter
dim_date["month"]   = dim_date["date_key"].dt.month
dim_date["day"]     = dim_date["date_key"].dt.day
dim_date["dow"]     = dim_date["date_key"].dt.weekday

# 4) Load dimensions
dim_customer = customers.rename(columns={"customer_city":"city","customer_state":"state"})[
    ["customer_id","customer_unique_id","city","state"]
]
dim_seller = sellers.rename(columns={"seller_city":"city","seller_state":"state"})[
    ["seller_id","city","state"]
]
dim_product = products[[
    "product_id","category_name","category_name_english",
    "product_weight_g","product_length_cm","product_height_cm","product_width_cm"
]].rename(columns={
    "product_weight_g":"weight_g","product_length_cm":"length_cm",
    "product_height_cm":"height_cm","product_width_cm":"width_cm"
})

with engine.begin() as conn:
    dim_date.to_sql("dim_date", conn, schema="olist", if_exists="append", index=False, method="multi")
    dim_customer.to_sql("dim_customer", conn, schema="olist", if_exists="append", index=False, method="multi")
    dim_seller.to_sql("dim_seller", conn, schema="olist", if_exists="append", index=False, method="multi")
    dim_product.to_sql("dim_product", conn, schema="olist", if_exists="append", index=False, method="multi")

# 5) Build surrogate key maps
def key_map(schema, table, key_col, natural_col):
    q = f"SELECT {key_col}, {natural_col} FROM {schema}.{table};"
    df = pd.read_sql(q, engine)
    return dict(zip(df[natural_col], df[key_col]))

cust_map   = key_map("olist","dim_customer","customer_key","customer_id")
seller_map = key_map("olist","dim_seller","seller_key","seller_id")
prod_map   = key_map("olist","dim_product","product_key","product_id")

# 6) Assemble fact_order_item
o = orders.rename(columns={
    "order_purchase_timestamp":"order_purchase_date"
})
i = items.rename(columns={})

fact = i.merge(o[["order_id","customer_id","order_purchase_date","order_approved_at",
                  "order_delivered_carrier_date","order_delivered_customer_date",
                  "order_estimated_delivery_date"]], on="order_id", how="left")

fact["customer_key"] = fact["customer_id"].map(cust_map)
fact["seller_key"]   = fact["seller_id"].map(seller_map)
fact["product_key"]  = fact["product_id"].map(prod_map)

for c in ["order_purchase_date","order_approved_at","order_delivered_carrier_date",
          "order_delivered_customer_date","order_estimated_delivery_date","shipping_limit_date"]:
    fact[c] = pd.to_datetime(fact[c]).dt.date

fact["revenue"] = fact["price"].fillna(0) - 0 + 0  # discount not present in Olist items; revenue â‰ˆ price
fact_fact = fact[[
    "order_id","order_item_id","customer_key","seller_key","product_key",
    "order_purchase_date","order_approved_at","order_delivered_carrier_date",
    "order_delivered_customer_date","order_estimated_delivery_date","shipping_limit_date",
    "price","freight_value","revenue"
]]

with engine.begin() as conn:
    fact_fact.to_sql("fact_order_item", conn, schema="olist", if_exists="append", index=False, method="multi", chunksize=5000)

# 7) Payments & reviews facts
with engine.begin() as conn:
    payments.to_sql("fact_payment", conn, schema="olist", if_exists="append", index=False, method="multi")
    rv = reviews.rename(columns={
        "review_comment_message":"comment"
    })[["review_id","order_id","review_score","review_creation_date","review_answer_timestamp"]]
    rv.to_sql("fact_review", conn, schema="olist", if_exists="append", index=False, method="multi")

