{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7735a51e-5356-4028-b001-bf3ed4605c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('twh', 'olist')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# Clean any libpq overrides that force TCP/login as 'postgres'\n",
    "load_dotenv(override=True)\n",
    "for k in (\"PGHOST\",\"PGUSER\",\"PGPASSWORD\",\"PGPORT\",\"PGDATABASE\"):\n",
    "    os.environ.pop(k, None)\n",
    "\n",
    "DSN = \"postgresql+psycopg2://twh@/olist?host=/tmp\"   # Homebrew default socket\n",
    "engine = create_engine(DSN, future=True)\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    print(conn.execute(text(\"select current_user, current_database()\")).all())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a38b32f0-e062-42d9-b108-0bfd3c1875f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'engine' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m schema_path \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/twh/Desktop/store data proj/olist/sql/01_schema.sql\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# adjust if your path differs\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m schema_path\u001b[38;5;241m.\u001b[39mexists(), schema_path\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mengine\u001b[49m\u001b[38;5;241m.\u001b[39mbegin() \u001b[38;5;28;01mas\u001b[39;00m conn:\n\u001b[1;32m      5\u001b[0m     conn\u001b[38;5;241m.\u001b[39mexec_driver_sql(schema_path\u001b[38;5;241m.\u001b[39mread_text())\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'engine' is not defined"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "schema_path = Path(\"/Users/twh/Desktop/store data proj/olist/sql/01_schema.sql\")  # adjust if your path differs\n",
    "assert schema_path.exists(), schema_path\n",
    "with engine.begin() as conn:\n",
    "    conn.exec_driver_sql(schema_path.read_text())\n",
    "\n",
    "import pandas as pd\n",
    "pd.read_sql(\"select schemaname, tablename from pg_tables where schemaname='olist' order by 2\", engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59109d20-ad75-4993-a8eb-300eaa9ec74e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tbl</th>\n",
       "      <th>rows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dim_customer</td>\n",
       "      <td>99441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dim_date</td>\n",
       "      <td>1314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dim_product</td>\n",
       "      <td>32951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dim_seller</td>\n",
       "      <td>3095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fact_order_item</td>\n",
       "      <td>112650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fact_payment</td>\n",
       "      <td>103886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fact_review</td>\n",
       "      <td>98410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tbl    rows\n",
       "0     dim_customer   99441\n",
       "1         dim_date    1314\n",
       "2      dim_product   32951\n",
       "3       dim_seller    3095\n",
       "4  fact_order_item  112650\n",
       "5     fact_payment  103886\n",
       "6      fact_review   98410"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "DSN = \"postgresql+psycopg2://twh@/olist?host=/tmp\" \n",
    "engine = create_engine(DSN, future=True)\n",
    "pd.read_sql(\"select schemaname, tablename from pg_tables where schemaname='olist' order by 2\", engine)\n",
    "\n",
    "pd.read_sql(\"\"\"\n",
    "SELECT 'dim_customer' AS tbl, COUNT(*)::bigint AS rows FROM olist.dim_customer\n",
    "UNION ALL SELECT 'dim_product', COUNT(*) FROM olist.dim_product\n",
    "UNION ALL SELECT 'dim_seller', COUNT(*) FROM olist.dim_seller\n",
    "UNION ALL SELECT 'dim_date', COUNT(*) FROM olist.dim_date\n",
    "UNION ALL SELECT 'fact_order_item', COUNT(*) FROM olist.fact_order_item\n",
    "UNION ALL SELECT 'fact_payment', COUNT(*) FROM olist.fact_payment\n",
    "UNION ALL SELECT 'fact_review', COUNT(*) FROM olist.fact_review\n",
    "ORDER BY 1;\n",
    "\"\"\", engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b7048f9-ab3a-40f5-a5bc-c118f3740cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import text\n",
    "with engine.begin() as conn:\n",
    "    conn.execute(text(\"TRUNCATE olist.dim_customer RESTART IDENTITY CASCADE\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6de87fcb-e8f5-43d0-906e-8247dfc8290b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99441"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv = \"/Users/twh/Desktop/store data proj/data/olist_customers_dataset.csv\"\n",
    "df_cust = pd.read_csv(csv, usecols=[\"customer_id\",\"customer_unique_id\",\"customer_city\",\"customer_state\"]) \\\n",
    "            .rename(columns={\"customer_city\":\"city\",\"customer_state\":\"state\"}) \\\n",
    "            .drop_duplicates(\"customer_id\")\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    df_cust.to_sql(\"dim_customer\", conn, schema=\"olist\", if_exists=\"append\", index=False, method=\"multi\", chunksize=10000)\n",
    "\n",
    "len(df_cust)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f702cb-afad-4c6d-a200-1d206c2c26dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from sqlalchemy import text\n",
    "\n",
    "p = \"/Users/twh/Desktop/store data proj/data\"\n",
    "customers = pd.read_csv(\"/Users/twh/Desktop/store data proj/data/olist_customers_dataset.csv\")\n",
    "orders    = pd.read_csv(f\"{p}/olist_orders_dataset.csv\", parse_dates=[\n",
    "    \"order_purchase_timestamp\",\"order_approved_at\",\n",
    "    \"order_delivered_carrier_date\",\"order_delivered_customer_date\",\n",
    "    \"order_estimated_delivery_date\"\n",
    "])\n",
    "items     = pd.read_csv(f\"{p}/olist_order_items_dataset.csv\", parse_dates=[\"shipping_limit_date\"])\n",
    "payments  = pd.read_csv(f\"{p}/olist_order_payments_dataset.csv\")\n",
    "reviews   = pd.read_csv(f\"{p}/olist_order_reviews_dataset.csv\", parse_dates=[\n",
    "    \"review_creation_date\",\"review_answer_timestamp\"\n",
    "])\n",
    "products  = pd.read_csv(f\"{p}/olist_products_dataset.csv\")\n",
    "catmap    = pd.read_csv(f\"{p}/product_category_name_translation.csv\")\n",
    "sellers   = pd.read_csv(f\"{p}/olist_sellers_dataset.csv\")\n",
    "\n",
    "# products + category translation\n",
    "products = products.merge(catmap, how=\"left\",\n",
    "                          left_on=\"product_category_name\",\n",
    "                          right_on=\"product_category_name\").rename(\n",
    "    columns={\"product_category_name\":\"category_name\",\n",
    "             \"product_category_name_english\":\"category_name_english\"}\n",
    ")\n",
    "\n",
    "# ---- build dim_date from min/max over all date cols ----\n",
    "date_series = []\n",
    "for df, cols in [(orders, [\"order_purchase_timestamp\",\"order_approved_at\",\n",
    "                           \"order_delivered_carrier_date\",\"order_delivered_customer_date\",\n",
    "                           \"order_estimated_delivery_date\"]),\n",
    "                 (items, [\"shipping_limit_date\"]),\n",
    "                 (reviews, [\"review_creation_date\",\"review_answer_timestamp\"])]:\n",
    "    for c in cols:\n",
    "        if c in df.columns:\n",
    "            date_series.append(pd.to_datetime(df[c]).dropna())\n",
    "\n",
    "if date_series:\n",
    "    dmin = min(s.min() for s in date_series).normalize()\n",
    "    dmax = max(s.max() for s in date_series).normalize()\n",
    "    dates = pd.date_range(dmin, dmax, freq=\"D\")\n",
    "    dim_date = pd.DataFrame({\"date_key\": dates})\n",
    "    dim_date[\"year\"]    = dim_date[\"date_key\"].dt.year\n",
    "    dim_date[\"quarter\"] = dim_date[\"date_key\"].dt.quarter\n",
    "    dim_date[\"month\"]   = dim_date[\"date_key\"].dt.month\n",
    "    dim_date[\"day\"]     = dim_date[\"date_key\"].dt.day\n",
    "    dim_date[\"dow\"]     = dim_date[\"date_key\"].dt.weekday\n",
    "else:\n",
    "    dim_date = pd.DataFrame(columns=[\"date_key\",\"year\",\"quarter\",\"month\",\"day\",\"dow\"])\n",
    "\n",
    "# ---- dims ----\n",
    "dim_customer = customers.rename(columns={\"customer_city\":\"city\",\"customer_state\":\"state\"})[\n",
    "    [\"customer_id\",\"customer_unique_id\",\"city\",\"state\"]\n",
    "].drop_duplicates(\"customer_id\")\n",
    "\n",
    "dim_seller = sellers.rename(columns={\"seller_city\":\"city\",\"seller_state\":\"state\"})[\n",
    "    [\"seller_id\",\"city\",\"state\"]\n",
    "].drop_duplicates(\"seller_id\")\n",
    "\n",
    "dim_product = products[[\n",
    "    \"product_id\",\"category_name\",\"category_name_english\",\n",
    "    \"product_weight_g\",\"product_length_cm\",\"product_height_cm\",\"product_width_cm\"\n",
    "]].rename(columns={\n",
    "    \"product_weight_g\":\"weight_g\",\"product_length_cm\":\"length_cm\",\n",
    "    \"product_height_cm\":\"height_cm\",\"product_width_cm\":\"width_cm\"\n",
    "}).drop_duplicates(\"product_id\")\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    # upserts naive: rely on empty tables (fresh load). For re-runs, you'd stage & merge.\n",
    "    dim_date.to_sql(\"dim_date\", conn, schema=\"olist\", if_exists=\"append\", index=False, method=\"multi\")\n",
    "    dim_customer.to_sql(\"dim_customer\", conn, schema=\"olist\", if_exists=\"append\", index=False, method=\"multi\")\n",
    "    dim_seller.to_sql(\"dim_seller\", conn, schema=\"olist\", if_exists=\"append\", index=False, method=\"multi\")\n",
    "    dim_product.to_sql(\"dim_product\", conn, schema=\"olist\", if_exists=\"append\", index=False, method=\"multi\")\n",
    "\n",
    "# --- FIXED key map helper + rebuild maps ---\n",
    "\n",
    "def key_map(schema: str, table: str, key_col: str, natural_col: str):\n",
    "    q = f'SELECT {key_col} AS sk, {natural_col} AS nk FROM {schema}.{table};'\n",
    "    df = pd.read_sql(q, engine)\n",
    "    # dict: natural key -> surrogate key\n",
    "    return dict(zip(df[\"nk\"], df[\"sk\"]))\n",
    "\n",
    "cust_map   = key_map(\"olist\", \"dim_customer\", \"customer_key\", \"customer_id\")\n",
    "seller_map = key_map(\"olist\", \"dim_seller\",   \"seller_key\",   \"seller_id\")\n",
    "prod_map   = key_map(\"olist\", \"dim_product\",  \"product_key\",  \"product_id\")\n",
    "\n",
    "# quick sanity checks\n",
    "print(\"cust_map:\", len(cust_map), \"seller_map:\", len(seller_map), \"prod_map:\", len(prod_map))\n",
    "\n",
    "\n",
    "# ---- fact_order_item ----\n",
    "o = orders.rename(columns={\"order_purchase_timestamp\":\"order_purchase_date\"})\n",
    "fact = items.merge(\n",
    "    o[[\"order_id\",\"customer_id\",\"order_purchase_date\",\"order_approved_at\",\n",
    "       \"order_delivered_carrier_date\",\"order_delivered_customer_date\",\n",
    "       \"order_estimated_delivery_date\"]],\n",
    "    on=\"order_id\", how=\"left\"\n",
    ")\n",
    "\n",
    "fact[\"customer_key\"] = fact[\"customer_id\"].map(cust_map)\n",
    "fact[\"seller_key\"]   = fact[\"seller_id\"].map(seller_map)\n",
    "fact[\"product_key\"]  = fact[\"product_id\"].map(prod_map)\n",
    "\n",
    "# Ensure dates are pure dates (match dim_date PK)\n",
    "for c in [\"order_purchase_date\",\"order_approved_at\",\"order_delivered_carrier_date\",\n",
    "          \"order_delivered_customer_date\",\"order_estimated_delivery_date\",\"shipping_limit_date\"]:\n",
    "    if c in fact.columns:\n",
    "        fact[c] = pd.to_datetime(fact[c]).dt.date\n",
    "\n",
    "# Olist has no discount at item level → revenue ≈ price\n",
    "fact[\"revenue\"] = fact[\"price\"].fillna(0)\n",
    "\n",
    "fact_items = fact[[\n",
    "    \"order_id\",\"order_item_id\",\"customer_key\",\"seller_key\",\"product_key\",\n",
    "    \"order_purchase_date\",\"order_approved_at\",\"order_delivered_carrier_date\",\n",
    "    \"order_delivered_customer_date\",\"order_estimated_delivery_date\",\"shipping_limit_date\",\n",
    "    \"price\",\"freight_value\",\"revenue\"\n",
    "]]\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    fact_items.to_sql(\"fact_order_item\", conn, schema=\"olist\", if_exists=\"append\",\n",
    "                      index=False, method=\"multi\", chunksize=10000)\n",
    "\n",
    "# ---- payments & reviews ----\n",
    "with engine.begin() as conn:\n",
    "    payments.to_sql(\"fact_payment\", conn, schema=\"olist\", if_exists=\"append\",\n",
    "                    index=False, method=\"multi\", chunksize=10000)\n",
    "\n",
    "    rv = reviews[[\"review_id\",\"order_id\",\"review_score\",\"review_creation_date\",\"review_answer_timestamp\"]]\n",
    "    # cast to date to match schema\n",
    "    for c in [\"review_creation_date\",\"review_answer_timestamp\"]:\n",
    "        rv[c] = pd.to_datetime(rv[c]).dt.date\n",
    "    rv.to_sql(\"fact_review\", conn, schema=\"olist\", if_exists=\"append\",\n",
    "              index=False, method=\"multi\", chunksize=10000)\n",
    "\n",
    "\"ETL done\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0efdad8-50ab-422a-902c-ced36078a2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def key_map(schema: str, table: str, key_col: str, natural_col: str):\n",
    "    q = f'SELECT {key_col} AS sk, {natural_col} AS nk FROM {schema}.{table};'\n",
    "    df = pd.read_sql(q, engine)\n",
    "    # dict: natural key -> surrogate key\n",
    "    return dict(zip(df[\"nk\"], df[\"sk\"]))\n",
    "\n",
    "cust_map   = key_map(\"olist\", \"dim_customer\", \"customer_key\", \"customer_id\")\n",
    "seller_map = key_map(\"olist\", \"dim_seller\",   \"seller_key\",   \"seller_id\")\n",
    "prod_map   = key_map(\"olist\", \"dim_product\",  \"product_key\",  \"product_id\")\n",
    "\n",
    "# quick sanity checks\n",
    "print(\"cust_map:\", len(cust_map), \"seller_map:\", len(seller_map), \"prod_map:\", len(prod_map))\n",
    "\n",
    "\n",
    "# ---- fact_order_item ----\n",
    "o = orders.rename(columns={\"order_purchase_timestamp\":\"order_purchase_date\"})\n",
    "fact = items.merge(\n",
    "    o[[\"order_id\",\"customer_id\",\"order_purchase_date\",\"order_approved_at\",\n",
    "       \"order_delivered_carrier_date\",\"order_delivered_customer_date\",\n",
    "       \"order_estimated_delivery_date\"]],\n",
    "    on=\"order_id\", how=\"left\"\n",
    ")\n",
    "\n",
    "fact[\"customer_key\"] = fact[\"customer_id\"].map(cust_map)\n",
    "fact[\"seller_key\"]   = fact[\"seller_id\"].map(seller_map)\n",
    "fact[\"product_key\"]  = fact[\"product_id\"].map(prod_map)\n",
    "\n",
    "# Ensure dates are pure dates (match dim_date PK)\n",
    "for c in [\"order_purchase_date\",\"order_approved_at\",\"order_delivered_carrier_date\",\n",
    "          \"order_delivered_customer_date\",\"order_estimated_delivery_date\",\"shipping_limit_date\"]:\n",
    "    if c in fact.columns:\n",
    "        fact[c] = pd.to_datetime(fact[c]).dt.date\n",
    "\n",
    "# Olist has no discount at item level → revenue ≈ price\n",
    "fact[\"revenue\"] = fact[\"price\"].fillna(0)\n",
    "\n",
    "fact_items = fact[[\n",
    "    \"order_id\",\"order_item_id\",\"customer_key\",\"seller_key\",\"product_key\",\n",
    "    \"order_purchase_date\",\"order_approved_at\",\"order_delivered_carrier_date\",\n",
    "    \"order_delivered_customer_date\",\"order_estimated_delivery_date\",\"shipping_limit_date\",\n",
    "    \"price\",\"freight_value\",\"revenue\"\n",
    "]]\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    fact_items.to_sql(\"fact_order_item\", conn, schema=\"olist\", if_exists=\"append\",\n",
    "                      index=False, method=\"multi\", chunksize=10000)\n",
    "\n",
    "# ---- payments & reviews ----\n",
    "with engine.begin() as conn:\n",
    "    payments.to_sql(\"fact_payment\", conn, schema=\"olist\", if_exists=\"append\",\n",
    "                    index=False, method=\"multi\", chunksize=10000)\n",
    "\n",
    "    rv = reviews[[\"review_id\",\"order_id\",\"review_score\",\"review_creation_date\",\"review_answer_timestamp\"]]\n",
    "    # cast to date to match schema\n",
    "    for c in [\"review_creation_date\",\"review_answer_timestamp\"]:\n",
    "        rv[c] = pd.to_datetime(rv[c]).dt.date\n",
    "    rv.to_sql(\"fact_review\", conn, schema=\"olist\", if_exists=\"append\",\n",
    "              index=False, method=\"multi\", chunksize=10000)\n",
    "\n",
    "\"ETL done\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e90f60c-95ff-4d9f-9d09-93ef231f7914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tbl</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dim_customer</td>\n",
       "      <td>99441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dim_date</td>\n",
       "      <td>1314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dim_product</td>\n",
       "      <td>32951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dim_seller</td>\n",
       "      <td>3095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fact_order_item</td>\n",
       "      <td>112650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fact_payment</td>\n",
       "      <td>103886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fact_review</td>\n",
       "      <td>98410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tbl   count\n",
       "0     dim_customer   99441\n",
       "1         dim_date    1314\n",
       "2      dim_product   32951\n",
       "3       dim_seller    3095\n",
       "4  fact_order_item  112650\n",
       "5     fact_payment  103886\n",
       "6      fact_review   98410"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_sql(\"\"\"\n",
    "SELECT 'dim_customer' AS tbl, COUNT(*)::bigint FROM olist.dim_customer\n",
    "UNION ALL SELECT 'dim_product', COUNT(*) FROM olist.dim_product\n",
    "UNION ALL SELECT 'dim_seller', COUNT(*) FROM olist.dim_seller\n",
    "UNION ALL SELECT 'dim_date', COUNT(*) FROM olist.dim_date\n",
    "UNION ALL SELECT 'fact_order_item', COUNT(*) FROM olist.fact_order_item\n",
    "UNION ALL SELECT 'fact_payment', COUNT(*) FROM olist.fact_payment\n",
    "UNION ALL SELECT 'fact_review', COUNT(*) FROM olist.fact_review\n",
    "ORDER BY 1;\n",
    "\"\"\", engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19cfc008-75cd-474d-b3d9-17562f2402d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103886"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "payments = pd.read_csv(f\"{p}/olist_order_payments_dataset.csv\")\n",
    "\n",
    "# keep only modeled columns & ensure uniqueness on the PK\n",
    "pay = payments[[\"order_id\",\"payment_sequential\",\"payment_type\",\"payment_installments\",\"payment_value\"]]\\\n",
    "         .drop_duplicates([\"order_id\",\"payment_sequential\"])\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    pay.to_sql(\"fact_payment\", conn, schema=\"olist\", if_exists=\"append\",\n",
    "               index=False, method=\"multi\", chunksize=50000)\n",
    "\n",
    "len(pay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22eb9edd-39a8-4888-8fa9-4dde516c3af2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98410"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = pd.read_csv(\n",
    "    f\"{p}/olist_order_reviews_dataset.csv\",\n",
    "    parse_dates=[\"review_creation_date\",\"review_answer_timestamp\"]\n",
    ")\n",
    "\n",
    "rv = reviews[[\"review_id\",\"order_id\",\"review_score\",\"review_creation_date\",\"review_answer_timestamp\"]]\\\n",
    "       .drop_duplicates(\"review_id\")\n",
    "\n",
    "# cast to DATE to match schema + FK to dim_date\n",
    "rv[\"review_creation_date\"]   = pd.to_datetime(rv[\"review_creation_date\"]).dt.date\n",
    "rv[\"review_answer_timestamp\"] = pd.to_datetime(rv[\"review_answer_timestamp\"]).dt.date\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    rv.to_sql(\"fact_review\", conn, schema=\"olist\", if_exists=\"append\",\n",
    "              index=False, method=\"multi\", chunksize=50000)\n",
    "\n",
    "len(rv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49e902c3-aa8c-4c11-aad4-1765d3417b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>revenue</th>\n",
       "      <th>orders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>267.36</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-10-01</td>\n",
       "      <td>49507.66</td>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-12-01</td>\n",
       "      <td>10.90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>120312.87</td>\n",
       "      <td>789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-02-01</td>\n",
       "      <td>247303.02</td>\n",
       "      <td>1733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>374344.30</td>\n",
       "      <td>2641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>359927.23</td>\n",
       "      <td>2391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2017-05-01</td>\n",
       "      <td>506071.14</td>\n",
       "      <td>3660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>433038.60</td>\n",
       "      <td>3217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017-07-01</td>\n",
       "      <td>498031.48</td>\n",
       "      <td>3969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2017-08-01</td>\n",
       "      <td>573971.68</td>\n",
       "      <td>4293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>624401.69</td>\n",
       "      <td>4243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2017-10-01</td>\n",
       "      <td>664219.43</td>\n",
       "      <td>4568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2017-11-01</td>\n",
       "      <td>1010271.37</td>\n",
       "      <td>7451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>743914.17</td>\n",
       "      <td>5624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>950030.36</td>\n",
       "      <td>7220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>844178.71</td>\n",
       "      <td>6694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2018-03-01</td>\n",
       "      <td>983213.44</td>\n",
       "      <td>7188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2018-04-01</td>\n",
       "      <td>996647.75</td>\n",
       "      <td>6934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2018-05-01</td>\n",
       "      <td>996517.68</td>\n",
       "      <td>6853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>865124.31</td>\n",
       "      <td>6160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2018-07-01</td>\n",
       "      <td>895507.22</td>\n",
       "      <td>6273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>854686.33</td>\n",
       "      <td>6452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>145.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         month     revenue  orders\n",
       "0   2016-09-01      267.36       3\n",
       "1   2016-10-01    49507.66     308\n",
       "2   2016-12-01       10.90       1\n",
       "3   2017-01-01   120312.87     789\n",
       "4   2017-02-01   247303.02    1733\n",
       "5   2017-03-01   374344.30    2641\n",
       "6   2017-04-01   359927.23    2391\n",
       "7   2017-05-01   506071.14    3660\n",
       "8   2017-06-01   433038.60    3217\n",
       "9   2017-07-01   498031.48    3969\n",
       "10  2017-08-01   573971.68    4293\n",
       "11  2017-09-01   624401.69    4243\n",
       "12  2017-10-01   664219.43    4568\n",
       "13  2017-11-01  1010271.37    7451\n",
       "14  2017-12-01   743914.17    5624\n",
       "15  2018-01-01   950030.36    7220\n",
       "16  2018-02-01   844178.71    6694\n",
       "17  2018-03-01   983213.44    7188\n",
       "18  2018-04-01   996647.75    6934\n",
       "19  2018-05-01   996517.68    6853\n",
       "20  2018-06-01   865124.31    6160\n",
       "21  2018-07-01   895507.22    6273\n",
       "22  2018-08-01   854686.33    6452\n",
       "23  2018-09-01      145.00       1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Payment mix\n",
    "pd.read_sql(\"\"\"\n",
    "SELECT payment_type, COUNT(*) AS payments, SUM(payment_value) AS value\n",
    "FROM olist.fact_payment\n",
    "GROUP BY 1\n",
    "ORDER BY value DESC;\n",
    "\"\"\", engine)\n",
    "\n",
    "# Review score distribution\n",
    "pd.read_sql(\"\"\"\n",
    "SELECT review_score, COUNT(*) AS reviews\n",
    "FROM olist.fact_review\n",
    "GROUP BY 1\n",
    "ORDER BY 1;\n",
    "\"\"\", engine)\n",
    "\n",
    "# Monthly revenue & orders\n",
    "pd.read_sql(\"\"\"\n",
    "SELECT date_trunc('month', order_purchase_date)::date AS month,\n",
    "       SUM(revenue) AS revenue,\n",
    "       COUNT(DISTINCT order_id) AS orders\n",
    "FROM olist.fact_order_item\n",
    "GROUP BY 1 ORDER BY 1;\n",
    "\"\"\", engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae932da3-aa45-404b-bd47-99dbf3d76c7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Saved reports/monthly_sales.xlsx'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_sql(\"\"\"\n",
    "SELECT date_trunc('month', order_purchase_date)::date AS month,\n",
    "       SUM(revenue) AS revenue,\n",
    "       COUNT(DISTINCT order_id) AS orders\n",
    "FROM olist.fact_order_item\n",
    "GROUP BY 1 ORDER BY 1;\n",
    "\"\"\", engine)\n",
    "with pd.ExcelWriter(\"/Users/twh/Desktop/store data proj/reports/monthly_sales.xlsx\") as xw:\n",
    "    df.to_excel(xw, index=False, sheet_name=\"Revenue by Month\")\n",
    "\"Saved reports/monthly_sales.xlsx\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c6965b-54d1-4f25-964c-483ba5bf42d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
